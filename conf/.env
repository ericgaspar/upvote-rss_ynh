# Reddit username for API requests
# Default value: (empty)
REDDIT_USER=your_reddit_username

# Reddit API client ID
# Default value: (empty)
REDDIT_CLIENT_ID=your_reddit_client_id

# Reddit API client secret
# Default value: (empty)
REDDIT_CLIENT_SECRET=your_reddit_client_secret

# Ollama URL
# URL to your Ollama instance for article summaries
# Default value: (empty)
OLLAMA_URL=your_ollama_url

# Ollama model
# Model used for article summaries
# Default value: (empty)
OLLAMA_MODEL=specified_ollama_model

# Google Gemini API key
# Used to connect to Google Gemini for article summaries when the "Include summary" checkbox is checked
# Default value: (empty)
GOOGLE_GEMINI_API_KEY=your_google_gemini_api_key

# Google Gemini API model
# Model used for article summaries
# Default value: gemini-2.5-flash
GOOGLE_GEMINI_API_MODEL=specified_google_gemini_model

# OpenAI API key
# Used to connect to OpenAI for article summaries when the "Include summary" checkbox is checked
# Default value: (empty)
OPENAI_API_KEY=your_openai_api_key

# OpenAI API model
# Model used for article summaries
# Default value: gpt-4o-mini
OPENAI_API_MODEL=specified_openai_model

# Anthropic API key
# Used to connect to Anthropic for article summaries when the "Include summary" checkbox is checked
# Default value: (empty)
ANTHROPIC_API_KEY=your_anthropic_api_key

# Anthropic API model
# Model used for article summaries
# Default value: claude-3-haiku-20240307
ANTHROPIC_API_MODEL=specified_anthropic_model

# Mistral API key
# Used to connect to Mistral for article summaries when the "Include summary" checkbox is checked
# Default value: (empty)
MISTRAL_API_KEY=your_mistral_api_key

# Mistral API model
# Model used for article summaries
# Default value: mistral-small-latest
MISTRAL_API_MODEL=specified_mistral_model

# DeepSeek API key
# Used to connect to DeepSeek for article summaries when the "Include summary" checkbox is checked
# Default value: (empty)
DEEPSEEK_API_KEY=your_deepseek_api_key

# DeepSeek API model
# Model used for article summaries
# Default value: deepseek-chat
DEEPSEEK_API_MODEL=specified_deepseek_model

# OpenAI-compatible API URL
# Used to connect to an OpenAI-compatible provider for article summaries when the "Include summary" checkbox is checked. This should be the full URL to the completions endpoint. For example, the one at OpenRouter is https://openrouter.ai/api/v1/chat/completions.
# Default value: (empty)
OPENAI_COMPATIBLE_URL=your_openai_compatible_url

# OpenAI-compatible API key
# Used to connect to an OpenAI-compatible provider for article summaries when the "Include summary" checkbox is checked.
# Default value: (empty)
OPENAI_COMPATIBLE_API_KEY=your_openai_compatible_api_key

# OpenAI-compatible API model
# Model used for article summaries
# Default value: (empty)
OPENAI_COMPATIBLE_API_MODEL=specified_openai_compatible_model

# Summary system prompt
# The prompt that guides the LLM model to give accurate-ish and concise article summaries
# Default value: You are web article summarizer. Use the following pieces of retrieved context to answer the question. Do not answer from your own knowledge base. If the answer isn't present in the knowledge base, refrain from providing an answer based on your own knowledge. Instead, say nothing. Output should be limited to one paragraph with a maximum of three sentences, and keep the answer concise. Always complete the last sentence. Do not hallucinate or make up information.
SUMMARY_SYSTEM_PROMPT="As GLaDOS, provide a concise and analytical summary of the following article, highlighting the key points while injecting a touch of sardonic wit and a hint of detached, almost clinical observation, as if dissecting a particularly uninteresting specimen."

# Summary temperature
# Change the LLM temperature to increase or decrease the randomness of text that is generated by the LLM during inference. A higher temperature is more creative but can be less consistent and coherent.
# Default value: 0.4
SUMMARY_TEMPERATURE=0.4

# Summary max tokens
# Set a maximum number of tokens the LLM will use to generate a response.
# Default value: 1000
SUMMARY_MAX_TOKENS=1000

# Redis host
# Redis instance IP address or domain used for API and webpage caching which will override the default filesystem caching method
# Default value: (empty)
REDIS_HOST=192.168.1.123

# Redis port
# Specify an optional Redis port if the REDIS_HOST variable is set and a non-standard port is used
# Default value: 6379
REDIS_PORT=6379

# Browserless URL
# The URL to a Browserless instance. Useful for getting article content for stubborn webpages that require JS for articles to load, among other things.
# Default value: (empty)
BROWSERLESS_URL=http://192.168.1.123:3000

# Browserless token
# The token to your Browserless instance if the BROWSERLESS_URL variable is set
# Default value: (empty)
BROWSERLESS_TOKEN=your_browserless_token

# Readability JS server URL
# The URL to a Readability JS server instance. Can provide better article parsing than the built-in Readability.php parser.
# Default value: (empty)
READABILITY_JS_URL=http://192.168.1.123:3000

# Mercury Parser server URL
# The URL to a Mercury Parser server instance. Can provide better article parsing than the built-in Readability.php parser.
# Default value: (empty)
MERCURY_URL=http://192.168.1.123:3000

# Clear webpages with cache
# When set to false, this prevents cached webpage content from being deleted when the "Refresh cache" link is clicked
# Default value: true
CLEAR_WEBPAGES_WITH_CACHE=false

# Max execution time
# Override the default timeout when generating RSS feeds. Useful especially if AI summaries cause the request to time out.
# Default value: 60
MAX_EXECUTION_TIME=300

# User and Group ID
# Override the default umask settings to set the proper permissions for the cache directory when mounted through Docker
# Default value: 1000
USER_ID=1000
GROUP_ID=1000

# Timezone
# Override the default timezone. Useful for viewing log messages.
# Default value: Europe/London
TZ=Europe/Paris